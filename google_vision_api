#!/usr/bin/env python
from IPython.display import display
import io
import os
from google.cloud import vision
from google.cloud.vision_v1 import types
import pandas as pd
from PIL import Image
import tempfile
from PIL import Image
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from io import BytesIO
#ignore warning, can be remove
import warnings
warnings.filterwarnings("ignore")
from PIL import Image, ImageFilter, ImageEnhance
import requests
import json
import urllib.request
import csv
import yaml

config_file_path = 'config.yml'
with open(config_file_path, 'r') as file:
    config = yaml.safe_load(file)

# Accessing configuration data
csv_input_file = config['csv_input_file']
csv_output_file = config['csv_output_file']
font_path = config['font_path']
image_directory_path = config['image_directory_path']
GOOGLE_APPLICATION_CREDENTIALS = config['GOOGLE_APPLICATION_CREDENTIALS']
MODE = config['MODE']
# please see the google_API_intro.pdf to see how to get api key json file
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = GOOGLE_APPLICATION_CREDENTIALS


# read csv from input node and return link
def read_csv_from_node(csv_input_file):
    data = pd.read_csv(csv_input_file)
    return(data)
# return Example
'''
   Node_id                 Title          Language
0    16264             Sushi One  English,Japanese
1    16267  Harden & L. C. Corp.   English,Chinese
2    16270              Sung Lin   English,Chinese
'''

# process data from node
def process_node(node_id):
    res = {}
    with urllib.request.urlopen("https://menus.digital.utsc.utoronto.ca/node/" + str(node_id) + "/children_rest") as url:
        node_data_from_link = json.load(url)
        # if node id is incorrect (unable to access) skip
        # from the web end the page will return []
        if len(node_data_from_link) > 1:
            for node_data in node_data_from_link:
                res[node_data['nid']] = {'Media_id':node_data['field_islandora_object_media'] , 'Title':node_data['title']}
            return res
        return 0

# access link after read_csv_from_node 
import urllib.request, json 
def access_node(data):
    # access from node
    res = {}
    for node_id in data['Node_id']:
        # if def process_node return is not equal 0 update date to res 
        if process_node(node_id) != 0:
            res.update(process_node(node_id))
    return res

# example return
'''
{'16266': {'Media_id': '36086', 'Title': 'Sushi One - Page 1'}, 
'16265': {'Media_id': '36085', 'Title': 'Sushi One - Page 2'}, 
'16268': {'Media_id': '36087', 'Title': 'Harden &amp; L. C. Corp. - Page 1'}, 
'16269': {'Media_id': '36088', 'Title': 'Harden &amp; L. C. Corp. - Page 2'}, 
'16272': {'Media_id': '36090', 'Title': 'Sung Lin - Page 1'}, 
'16271': {'Media_id': '36089', 'Title': 'Sung Lin - Page 2'}}
'''

# process media after we have the result for access_node
def process_media(nid_title_media_id):
    for nid in list(nid_title_media_id.keys()):
        with urllib.request.urlopen("https://menus.digital.utsc.utoronto.ca/media/" + str((nid_title_media_id[nid]['Media_id'])) + "?_format=json") as url:
            media_data_from_link = json.load(url)
            target_id = media_data_from_link.get('field_media_image')[0]['target_id']
            # if target_id is not empty add target_id else remove node id
            if (target_id) > 0:
                nid_title_media_id[nid]['target_id'] = target_id
            else:
                del nid_title_media_id[nid]
    return(nid_title_media_id)
# return example
'''
{'16266': {'Media_id': '36086', 'Title': 'Sushi One - Page 1', 'target_id': 59809}, 
'16265': {'Media_id': '36085', 'Title': 'Sushi One - Page 2', 'target_id': 59806}, 
'16268': {'Media_id': '36087', 'Title': 'Harden &amp; L. C. Corp. - Page 1', 'target_id': 59812}, 
'16269': {'Media_id': '36088', 'Title': 'Harden &amp; L. C. Corp. - Page 2', 'target_id': 59815}, 
'16272': {'Media_id': '36090', 'Title': 'Sung Lin - Page 1', 'target_id': 59821}, 
'16271': {'Media_id': '36089', 'Title': 'Sung Lin - Page 2', 'target_id': 59818}}
'''

def process_file(mid_data):
    for nid in list(mid_data.keys()):
        with urllib.request.urlopen("https://menus.digital.utsc.utoronto.ca/file/" + str((mid_data[nid]['target_id'])) + "?_format=json") as url:
            media_data_from_link = json.load(url)
            url_link = media_data_from_link['uri'][0]['url']
            local_file_name = url_link.split('/')[-1]         
            mid_data[nid]['local_path'] = local_file_name
            response = requests.get("https://menus.digital.utsc.utoronto.ca" + url_link)
            if response.status_code == 200:
                with open(local_file_name, 'wb') as file:
                    file.write(response.content)

# save file to local path and full out format csv. Input csv
def get_mid_data(csv_input_file):
    node_data = read_csv_from_node(csv_input_file)
    nid_title_media_id = access_node(node_data)
    mid_data =  process_media(nid_title_media_id)
    return mid_data
def download_file(csv_input_file):
    mid_data = get_mid_data(csv_input_file)
    process_file(mid_data)

# read all the images from directory or local path
def find_all_img_path(directory_path):
    image_extensions = ['.jpg', '.png', '.jp2', '.tiff']
    image_paths = []
    desired_prefix = 'OBJ.0_'
    # Walk through the directory
    for root, dirs, files in os.walk(directory_path):
        for file in files:
            full_path = os.path.join(root, file)
            if any(file.endswith(ext) for ext in image_extensions) and desired_prefix in file:
                if root == directory_path:
                    image_paths.append(full_path)

    return image_paths
# return example
'''
['C:\\Users\\zxx91\\OBJ.0_10762.jp2', 
'C:\\Users\\zxx91\\OBJ.0_10763.jp2', 
'C:\\Users\\zxx91\\OBJ.0_10764.jp2', 
'C:\\Users\\zxx91\\OBJ.0_10765.jp2', 
'C:\\Users\\zxx91\\OBJ.0_10766.jp2', 
'C:\\Users\\zxx91\\OBJ.0_10767.jp2']
'''

# Initialize the client for the Vision API
client = vision.ImageAnnotatorClient()
def detectText(img):
    # Check if the file is a JP2 file
    with Image.open(img) as opened_image:
        # Convert to RGB if not already in JPEG format (necessary for non-JPEG formats)
        if opened_image.format != 'JPEG':
            with io.BytesIO() as output:
                opened_image.convert('RGB').save(output, format="JPEG")
                content = output.getvalue()
        else:
            # For JPEG (including JP2 handled by Pillow), read directly
            with io.open(img, 'rb') as image_file:
                content = image_file.read()
    # Prepare the image for the Vision API
    image = types.Image(content=content)

    # Perform text detection
    response = client.text_detection(image=image)
    texts = response.text_annotations
    return texts

# read all images path from local path and save to target path
def save_json(image_directory_path):
    all_img_path = find_all_img_path(image_directory_path)
    json_file_path = []
    for img in all_img_path:
        response = detectText(img)
        json_file_name = img.replace('.jp2', '.json')
        json_file_path = json_file_path + [json_file_name]
        # Extracting the data from the response
        extracted_data = [{
            'description': text.description,
            'boundingPoly': [{'x': vertex.x, 'y': vertex.y} for vertex in text.bounding_poly.vertices]
        } for text in response]

        # Writing the extracted data to a JSON file
        with open(json_file_name, 'w', encoding='utf-8') as file:
            json.dump(extracted_data, file, ensure_ascii=False, indent=4)
    return json_file_path

# generate pdf/A with selectable text and return file name
def create_pdf_with_selectable_text(image_directory_path, texts, font_path):
    pdfmetrics.registerFont(TTFont('NotoSans', font_path))
    # Open the image and get its dimensions
    with Image.open(image_directory_path) as img:
        img_width, img_height = img.size
        scale_w = letter[0] / img_width
        scale_h = letter[1] / img_height
        # Save the image to a temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_img_file:
            img.save(temp_img_file, format='JPEG')
            temp_img_path = temp_img_file.name
        # Create a PDF
        pdf_path = image_directory_path.replace('.jp2', '.pdf')
        c = canvas.Canvas(pdf_path, pagesize=letter)
        # Add the image to the PDF
        c.drawImage(temp_img_path, 0, 0, width=letter[0], height=letter[1])
        # Add invisible text objects to the PDF
        for text in texts[1:]:  # Skip the first element
            vertices = [(int(vertex.x * scale_w), int(vertex.y * scale_h)) for vertex in text.bounding_poly.vertices]
            x0, y0 = vertices[0]
            y0 = letter[1] - y0 - (text.bounding_poly.vertices[2].y - text.bounding_poly.vertices[0].y) * scale_h

            # Set font size, invisible fill color and write text
            c.setFont("NotoSans", 12)
            c.setFillColorRGB(0, 0, 0, alpha=0)
            c.drawString(x0, y0, text.description)
        # Finalize the PDF
        c.save()
        # Remove the temporary image file
        os.remove(temp_img_path)
    return pdf_path

# call create_pdf_with_selectable_text to process all images from target image path
def generate_pdf(image_directory_path):
    all_img_path = find_all_img_path(image_directory_path)
    pdf_file_path = []
    for img in all_img_path:
        response = detectText(img)
        pdf_file = create_pdf_with_selectable_text(img, response, font_path)
        pdf_file_path = pdf_file_path + [pdf_file]
    return pdf_file_path

# generate both json and pdf
def both_json_pdf(image_directory_path):
    json_file_path = save_json(image_directory_path)
    pdf_A_file_path = generate_pdf(image_directory_path)
    return json_file_path, pdf_A_file_path

# write csv file
def write_csv(csv_output_file, transformed_data, headers):
    with open(csv_output_file, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=headers)
        writer.writeheader()
        for row in transformed_data:
            row.pop('local_path', None) 
            writer.writerow(row)

# output csv with json
def output_csv_json(csv_input_file, csv_output_file, image_directory_path):
    mid_data = get_mid_data(csv_input_file)
    all_img_path = find_all_img_path(image_directory_path)
    json_file_path = save_json(image_directory_path)
    transformed_data = []
    headers = ["Node_id", "Title", "Media_id", "Local_File_Path", "OCR_File_Path"]
    for (node_id, details), img_file, json_file in zip(mid_data.items(), all_img_path, json_file_path):
        row = details.copy()
        row['Node_id'] = node_id
        row['Local_File_Path'] = img_file
        row['OCR_File_Path'] = json_file
        row.pop('target_id', None)
        transformed_data.append(row)
    write_csv(csv_output_file, transformed_data, headers)

# output csv with pdf/A
def output_csv_pdf(csv_input_file, csv_output_file, image_directory_path):
    mid_data = get_mid_data(csv_input_file)
    all_img_path = find_all_img_path(image_directory_path)
    pdf_file_path = generate_pdf(image_directory_path)
    transformed_data = []
    headers = ["Node_id", "Title", "Media_id", "Local_File_Path", "PDF_File"]
    for (node_id, details), img_file, pdf_file in zip(mid_data.items(), all_img_path, pdf_file_path):
        row = details.copy()
        row['Node_id'] = node_id
        row['Local_File_Path'] = img_file
        row['PDF_File'] = pdf_file
        row.pop('target_id', None)
        transformed_data.append(row)
    write_csv(csv_output_file, transformed_data, headers)

# output csv with pdf/A and json
def output_csv_pdf_json(csv_input_file, csv_output_file, image_directory_path):
    mid_data = get_mid_data(csv_input_file)
    json_file_path = save_json(image_directory_path)
    all_img_path = find_all_img_path(image_directory_path)
    pdf_file_path = generate_pdf(image_directory_path)
    transformed_data = []
    headers = ["Node_id", "Title", "Media_id", "Local_File_Path", "OCR_File_Path", "PDF_File"]
    for (node_id, details), img_file, json_file, pdf_file in zip(mid_data.items(), all_img_path, json_file_path, pdf_file_path):
        row = details.copy()
        row['Node_id'] = node_id
        row['Local_File_Path'] = img_file
        row['OCR_File_Path'] = json_file
        row['PDF_File'] = pdf_file
        row.pop('target_id', None)
        transformed_data.append(row)
    write_csv(csv_output_file, transformed_data, headers)

# select output mode
def output_mode(MODE='json'):
    if MODE == 'json':
        output_csv_json(csv_input_file, csv_output_file, image_directory_path)
        print(MODE, "completed")
    elif MODE == 'pdf':
        output_csv_pdf(csv_input_file, csv_output_file, image_directory_path)
        print(MODE, "completed")
    elif MODE == 'pdf_json' or MODE == 'json_pdf':
        output_csv_pdf_json(csv_input_file, csv_output_file, image_directory_path)
        print(MODE, "completed")
    elif MODE == 'download':
        download_file(csv_input_file)
        print(MODE, "completed")
    else:
        print("Please try again mode should be 1. <download>, 2. <json>, <pdf>, <json_pdf>/<pdf_json>")

output_mode(MODE)
